model_config:
  clip_model_path: "../models/clip-vit-base-patch32/"
  llm_model_path: "../models/flan-t5-base/"
  detection_model_path: "../models/DETR/"

data_config:
  coco_images_dir: "/home/m025/qqw/coco/train2017/"
  coco_annotations_path: "/home/m025/qqw/coco/annotations/captions_train2017.json"

retrieval_config:
  top_k: 3
  use_patch_retrieval: true  # 启用分块检索功能

generation_config:
  max_length: 20
  num_beams: 2

runtime_config:
  # 'deploy' -> on generation failure, use fallback composed from retrieved captions
  # 'test'   -> on generation failure, print a failure message
  mode: "test"

knowledge_base_config:
  knowledge_base_path: "./output/coco_knowledge_base.faiss"
  image_id_to_captions_path: "./output/image_id_to_captions.pkl"

log_config:
  log_level: "ERROR"

patch_config:
  # 目标检测配置
  detection_confidence_threshold: 0.7  # 检测置信度阈值
  max_local_regions: 5  # 最大局部区域数量
  expand_ratio: 0.1  # 边界框扩展比例
  
  # 局部检索配置
  local_retrieval_top_k: 1  # 每个局部区域检索的top_k

  # 调试选项
  save_debug_patches: true  # 是否保存检测到的区域图像用于调试

lora_config:
  enabled: true
  weights_path: "lora_training/checkpoints"  # LoRA 适配器路径
  merge_and_unload: false

evaluation:
  val_images_dir: "/home/m025/qqw/coco/val2017/"
  val_annotations_path: "/home/m025/qqw/coco/annotations/captions_val2017.json"
  subset_size: null
  output_dir: "./evaluation_results/"
  save_individual_results: true

metrics:
  bleu: true
  rouge: true
  cider: true
  spice: false

description_optimization:
  enabled: true
  embedding_model: "../models/all-MiniLM-L6-v2/"
  max_final_descriptions: 5
  clustering_algorithm: "hdbscan"
  min_cluster_size: 2
  score_weights:
    cluster_similarity: 0.4
    image_similarity: 0.4
    brevity: 0.2
  hdbscan:
    min_samples: 1
    cluster_selection_epsilon: 0.1
