model_config:
  clip_model_path: "../models/clip-vit-base-patch32/"
  llm_model_path: "../models/Qwen2.5-3B-instruct/"
  detection_model_path: "../models/DETR/"

data_config:
  coco_images_dir: "/home/m025/qqw/coco/train2017/"
  coco_annotations_path: "/home/m025/qqw/coco/annotations/captions_train2017.json"

retrieval_config:
  top_k: 3
  use_patch_retrieval: true  # 启用分块检索功能

generation_config:
  max_length: 100
  num_beams: 3

runtime_config:
  # 'deploy' -> on generation failure, use fallback composed from retrieved captions
  # 'test'   -> on generation failure, print a failure message
  mode: "test"

knowledge_base_config:
  knowledge_base_path: "./output/coco_knowledge_base.faiss"
  image_id_to_captions_path: "./output/image_id_to_captions.pkl"

log_config:
  log_level: "ERROR"

patch_config:
  # 目标检测配置
  detection_confidence_threshold: 0.7  # 检测置信度阈值
  max_local_regions: 5  # 最大局部区域数量
  expand_ratio: 0.1  # 边界框扩展比例
  
  # 局部检索配置
  local_retrieval_top_k: 1  # 每个局部区域检索的top_k

  # 调试选项
  save_debug_patches: true  # 是否保存检测到的区域图像用于调试
